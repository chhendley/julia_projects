{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the columns you want to select\n",
    "selected_columns = [\"SEED\", \"W\", \"ADJOE\", \"ADJDE\", \"BARTHAG\", \"EFG_O\", \"EFG_D\", \"TOR\", \"TORD\", \"ORB\", \"DRB\", \"FTR\", \"FTRD\", \"2P_O\", \"2P_D\", \"3P_O\", \"3P_D\", \"ADJ_T\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "featuer used last time:\n",
    "\n",
    "features_used = [\"Wins\", \"ADJOE\", \"ADJDE\", \"BARTHAG\", \"EFG%\", \"EFG%D\",\n",
    "                 \"TOR\", \"TORD\", \"ORB\", \"DRB\", \"FTR\", \"FTRD\", \"2P%\",\n",
    "                 \"2P%D\", \"3P%\", \"3P%D\", \"ADJ T.\", \"SEED\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature ranks\n",
    "[\"W\", \"ADJOE_rank\", \"ADJDE_rank\", \"BARTHAG_rank\", \"EFG%_rank\", \"EFGD%_rank\",\n",
    "\"TOR_rank\", \"TORD_rank\", \"ORB_rank\", \"DRB_rank\", \"FTR_rank\", \"FTRD_rank\", \"2P%_rank\",\n",
    "\"2P%D_rank\", \"3P%_rank\", \"3P%D_rank\", \"ADJ T._rank\", \"SEED\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>68Ã—46 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">43 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">RK</th><th style = \"text-align: left;\">TEAM</th><th style = \"text-align: left;\">CONF</th><th style = \"text-align: left;\">G</th><th style = \"text-align: left;\">WAB</th><th style = \"text-align: left;\">POSTSEASON</th><th style = \"text-align: left;\">SEED</th><th style = \"text-align: left;\">WINS</th><th style = \"text-align: left;\">LOSSES</th><th style = \"text-align: left;\">YEAR</th><th style = \"text-align: left;\">ADJOE</th><th style = \"text-align: left;\">ADJOE_rank</th><th style = \"text-align: left;\">ADJDE</th><th style = \"text-align: left;\">ADJDE_rank</th><th style = \"text-align: left;\">BARTHAG</th><th style = \"text-align: left;\">BARTHAG_rank</th><th style = \"text-align: left;\">EFG%</th><th style = \"text-align: left;\">EFG%_rank</th><th style = \"text-align: left;\">EFGD%</th><th style = \"text-align: left;\">EFGD%_rank</th><th style = \"text-align: left;\">TOR</th><th style = \"text-align: left;\">TOR_rank</th><th style = \"text-align: left;\">TORD</th><th style = \"text-align: left;\">TORD_rank</th><th style = \"text-align: left;\">ORB</th><th style = \"text-align: left;\">ORB_rank</th><th style = \"text-align: left;\">DRB</th><th style = \"text-align: left;\">DRB_rank</th><th style = \"text-align: left;\">FTR</th><th style = \"text-align: left;\">FTR_rank</th><th style = \"text-align: left;\">FTRD</th><th style = \"text-align: left;\">FTRD_rank</th><th style = \"text-align: left;\">2P%</th><th style = \"text-align: left;\">2P%_rank</th><th style = \"text-align: left;\">2P%D</th><th style = \"text-align: left;\">2P%D_rank</th><th style = \"text-align: left;\">3P%</th><th style = \"text-align: left;\">3P%_rank</th><th style = \"text-align: left;\">3P%D</th><th style = \"text-align: left;\">3P%D_rank</th><th style = \"text-align: left;\">3PR</th><th style = \"text-align: left;\">3PR_rank</th><th style = \"text-align: left;\">3PRD</th><th style = \"text-align: left;\">3PRD_rank</th><th style = \"text-align: left;\">ADJ T.</th><th style = \"text-align: left;\">ADJ T._rank</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String31\" style = \"text-align: left;\">String31</th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">95</td><td style = \"text-align: left;\">Akron</td><td style = \"text-align: left;\">MAC</td><td style = \"text-align: right;\">34</td><td style = \"text-align: left;\">-1.7\\n63</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">114.0</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">106.8</td><td style = \"text-align: right;\">182</td><td style = \"text-align: right;\">0.6782</td><td style = \"text-align: right;\">95</td><td style = \"text-align: right;\">55.4</td><td style = \"text-align: right;\">31</td><td style = \"text-align: right;\">49.5</td><td style = \"text-align: right;\">110</td><td style = \"text-align: right;\">16.6</td><td style = \"text-align: right;\">137</td><td style = \"text-align: right;\">17.2</td><td style = \"text-align: right;\">174</td><td style = \"text-align: right;\">33.3</td><td style = \"text-align: right;\">76</td><td style = \"text-align: right;\">29.0</td><td style = \"text-align: right;\">136</td><td style = \"text-align: right;\">26.8</td><td style = \"text-align: right;\">332</td><td style = \"text-align: right;\">33.7</td><td style = \"text-align: right;\">201</td><td style = \"text-align: right;\">55.8</td><td style = \"text-align: right;\">34</td><td style = \"text-align: right;\">50.6</td><td style = \"text-align: right;\">163</td><td style = \"text-align: right;\">36.6</td><td style = \"text-align: right;\">46</td><td style = \"text-align: right;\">31.9</td><td style = \"text-align: right;\">70</td><td style = \"text-align: right;\">45.4</td><td style = \"text-align: right;\">51</td><td style = \"text-align: right;\">38.0</td><td style = \"text-align: right;\">148</td><td style = \"text-align: right;\">71.2</td><td style = \"text-align: right;\">19</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">5</td><td style = \"text-align: left;\">Alabama</td><td style = \"text-align: left;\">SEC</td><td style = \"text-align: right;\">33</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">25</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">127.7</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">96.4</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">0.9621</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">56.3</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">47.9</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">16.7</td><td style = \"text-align: right;\">149</td><td style = \"text-align: right;\">13.5</td><td style = \"text-align: right;\">348</td><td style = \"text-align: right;\">34.7</td><td style = \"text-align: right;\">39</td><td style = \"text-align: right;\">29.2</td><td style = \"text-align: right;\">149</td><td style = \"text-align: right;\">40.1</td><td style = \"text-align: right;\">25</td><td style = \"text-align: right;\">33.9</td><td style = \"text-align: right;\">206</td><td style = \"text-align: right;\">59.7</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">48.8</td><td style = \"text-align: right;\">92</td><td style = \"text-align: right;\">35.0</td><td style = \"text-align: right;\">107</td><td style = \"text-align: right;\">30.8</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">46.2</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">35.1</td><td style = \"text-align: right;\">55</td><td style = \"text-align: right;\">74.7</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">275</td><td style = \"text-align: left;\">Alabama St.</td><td style = \"text-align: left;\">SWAC</td><td style = \"text-align: right;\">35</td><td style = \"text-align: left;\">-10.1\\n200</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">100.6</td><td style = \"text-align: right;\">282</td><td style = \"text-align: right;\">109.7</td><td style = \"text-align: right;\">247</td><td style = \"text-align: right;\">0.2682</td><td style = \"text-align: right;\">275</td><td style = \"text-align: right;\">47.1</td><td style = \"text-align: right;\">325</td><td style = \"text-align: right;\">50.6</td><td style = \"text-align: right;\">163</td><td style = \"text-align: right;\">13.1</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">18.7</td><td style = \"text-align: right;\">86</td><td style = \"text-align: right;\">28.3</td><td style = \"text-align: right;\">228</td><td style = \"text-align: right;\">30.7</td><td style = \"text-align: right;\">225</td><td style = \"text-align: right;\">29.1</td><td style = \"text-align: right;\">295</td><td style = \"text-align: right;\">38.5</td><td style = \"text-align: right;\">305</td><td style = \"text-align: right;\">45.6</td><td style = \"text-align: right;\">338</td><td style = \"text-align: right;\">50.5</td><td style = \"text-align: right;\">157</td><td style = \"text-align: right;\">32.8</td><td style = \"text-align: right;\">224</td><td style = \"text-align: right;\">33.8</td><td style = \"text-align: right;\">177</td><td style = \"text-align: right;\">42.8</td><td style = \"text-align: right;\">85</td><td style = \"text-align: right;\">39.6</td><td style = \"text-align: right;\">205</td><td style = \"text-align: right;\">67.6</td><td style = \"text-align: right;\">155</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">243</td><td style = \"text-align: left;\">American</td><td style = \"text-align: left;\">Pat</td><td style = \"text-align: right;\">34</td><td style = \"text-align: left;\">-8.2\\n165</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">101.3</td><td style = \"text-align: right;\">268</td><td style = \"text-align: right;\">107.4</td><td style = \"text-align: right;\">194</td><td style = \"text-align: right;\">0.3373</td><td style = \"text-align: right;\">243</td><td style = \"text-align: right;\">51.8</td><td style = \"text-align: right;\">119</td><td style = \"text-align: right;\">52.1</td><td style = \"text-align: right;\">242</td><td style = \"text-align: right;\">16.8</td><td style = \"text-align: right;\">155</td><td style = \"text-align: right;\">17.6</td><td style = \"text-align: right;\">139</td><td style = \"text-align: right;\">23.8</td><td style = \"text-align: right;\">335</td><td style = \"text-align: right;\">27.4</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">29.5</td><td style = \"text-align: right;\">288</td><td style = \"text-align: right;\">34.1</td><td style = \"text-align: right;\">211</td><td style = \"text-align: right;\">51.1</td><td style = \"text-align: right;\">170</td><td style = \"text-align: right;\">53.1</td><td style = \"text-align: right;\">268</td><td style = \"text-align: right;\">35.1</td><td style = \"text-align: right;\">102</td><td style = \"text-align: right;\">33.6</td><td style = \"text-align: right;\">165</td><td style = \"text-align: right;\">44.8</td><td style = \"text-align: right;\">57</td><td style = \"text-align: right;\">35.7</td><td style = \"text-align: right;\">76</td><td style = \"text-align: right;\">63.5</td><td style = \"text-align: right;\">349</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">9</td><td style = \"text-align: left;\">Arizona</td><td style = \"text-align: left;\">B12</td><td style = \"text-align: right;\">34</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">124.0</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">96.6</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">0.9463</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">52.9</td><td style = \"text-align: right;\">83</td><td style = \"text-align: right;\">48.6</td><td style = \"text-align: right;\">73</td><td style = \"text-align: right;\">16.2</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">16.6</td><td style = \"text-align: right;\">212</td><td style = \"text-align: right;\">35.9</td><td style = \"text-align: right;\">19</td><td style = \"text-align: right;\">28.5</td><td style = \"text-align: right;\">107</td><td style = \"text-align: right;\">36.6</td><td style = \"text-align: right;\">71</td><td style = \"text-align: right;\">29.2</td><td style = \"text-align: right;\">80</td><td style = \"text-align: right;\">55.1</td><td style = \"text-align: right;\">44</td><td style = \"text-align: right;\">47.2</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">32.4</td><td style = \"text-align: right;\">247</td><td style = \"text-align: right;\">33.6</td><td style = \"text-align: right;\">165</td><td style = \"text-align: right;\">34.6</td><td style = \"text-align: right;\">291</td><td style = \"text-align: right;\">41.9</td><td style = \"text-align: right;\">284</td><td style = \"text-align: right;\">69.9</td><td style = \"text-align: right;\">53</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">42</td><td style = \"text-align: left;\">Arkansas</td><td style = \"text-align: left;\">SEC</td><td style = \"text-align: right;\">33</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">112.0</td><td style = \"text-align: right;\">82</td><td style = \"text-align: right;\">95.5</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">0.8614</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">52.7</td><td style = \"text-align: right;\">88</td><td style = \"text-align: right;\">48.3</td><td style = \"text-align: right;\">60</td><td style = \"text-align: right;\">16.5</td><td style = \"text-align: right;\">132</td><td style = \"text-align: right;\">17.5</td><td style = \"text-align: right;\">151</td><td style = \"text-align: right;\">27.6</td><td style = \"text-align: right;\">245</td><td style = \"text-align: right;\">28.3</td><td style = \"text-align: right;\">97</td><td style = \"text-align: right;\">35.5</td><td style = \"text-align: right;\">107</td><td style = \"text-align: right;\">29.4</td><td style = \"text-align: right;\">85</td><td style = \"text-align: right;\">54.4</td><td style = \"text-align: right;\">61</td><td style = \"text-align: right;\">48.5</td><td style = \"text-align: right;\">81</td><td style = \"text-align: right;\">33.3</td><td style = \"text-align: right;\">199</td><td style = \"text-align: right;\">31.9</td><td style = \"text-align: right;\">70</td><td style = \"text-align: right;\">36.7</td><td style = \"text-align: right;\">242</td><td style = \"text-align: right;\">39.5</td><td style = \"text-align: right;\">202</td><td style = \"text-align: right;\">69.3</td><td style = \"text-align: right;\">67</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">3</td><td style = \"text-align: left;\">Auburn</td><td style = \"text-align: left;\">SEC</td><td style = \"text-align: right;\">33</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">129.2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">93.7</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">0.9756</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">55.7</td><td style = \"text-align: right;\">26</td><td style = \"text-align: right;\">46.0</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">13.4</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">17.4</td><td style = \"text-align: right;\">155</td><td style = \"text-align: right;\">34.3</td><td style = \"text-align: right;\">51</td><td style = \"text-align: right;\">30.3</td><td style = \"text-align: right;\">211</td><td style = \"text-align: right;\">33.5</td><td style = \"text-align: right;\">166</td><td style = \"text-align: right;\">39.2</td><td style = \"text-align: right;\">313</td><td style = \"text-align: right;\">56.1</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">47.2</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">36.8</td><td style = \"text-align: right;\">39</td><td style = \"text-align: right;\">29.2</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">40.6</td><td style = \"text-align: right;\">138</td><td style = \"text-align: right;\">34.8</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">67.8</td><td style = \"text-align: right;\">143</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">14</td><td style = \"text-align: left;\">BYU</td><td style = \"text-align: left;\">B12</td><td style = \"text-align: right;\">33</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">125.5</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">99.2</td><td style = \"text-align: right;\">53</td><td style = \"text-align: right;\">0.9369</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">57.2</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">50.6</td><td style = \"text-align: right;\">163</td><td style = \"text-align: right;\">17.6</td><td style = \"text-align: right;\">207</td><td style = \"text-align: right;\">17.2</td><td style = \"text-align: right;\">174</td><td style = \"text-align: right;\">33.3</td><td style = \"text-align: right;\">76</td><td style = \"text-align: right;\">26.1</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">30.2</td><td style = \"text-align: right;\">269</td><td style = \"text-align: right;\">29.5</td><td style = \"text-align: right;\">89</td><td style = \"text-align: right;\">58.6</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">49.3</td><td style = \"text-align: right;\">114</td><td style = \"text-align: right;\">37.1</td><td style = \"text-align: right;\">32</td><td style = \"text-align: right;\">34.8</td><td style = \"text-align: right;\">241</td><td style = \"text-align: right;\">48.3</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">44.4</td><td style = \"text-align: right;\">329</td><td style = \"text-align: right;\">67.3</td><td style = \"text-align: right;\">181</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">27</td><td style = \"text-align: left;\">Baylor</td><td style = \"text-align: left;\">B12</td><td style = \"text-align: right;\">33</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">19</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">120.6</td><td style = \"text-align: right;\">17</td><td style = \"text-align: right;\">99.4</td><td style = \"text-align: right;\">56</td><td style = \"text-align: right;\">0.9018</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">51.5</td><td style = \"text-align: right;\">135</td><td style = \"text-align: right;\">51.2</td><td style = \"text-align: right;\">196</td><td style = \"text-align: right;\">16.1</td><td style = \"text-align: right;\">103</td><td style = \"text-align: right;\">18.8</td><td style = \"text-align: right;\">81</td><td style = \"text-align: right;\">35.6</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">31.2</td><td style = \"text-align: right;\">250</td><td style = \"text-align: right;\">31.0</td><td style = \"text-align: right;\">239</td><td style = \"text-align: right;\">33.5</td><td style = \"text-align: right;\">196</td><td style = \"text-align: right;\">51.2</td><td style = \"text-align: right;\">168</td><td style = \"text-align: right;\">49.8</td><td style = \"text-align: right;\">128</td><td style = \"text-align: right;\">34.7</td><td style = \"text-align: right;\">125</td><td style = \"text-align: right;\">35.4</td><td style = \"text-align: right;\">276</td><td style = \"text-align: right;\">40.2</td><td style = \"text-align: right;\">146</td><td style = \"text-align: right;\">40.8</td><td style = \"text-align: right;\">249</td><td style = \"text-align: right;\">64.7</td><td style = \"text-align: right;\">314</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">153</td><td style = \"text-align: left;\">Bryant</td><td style = \"text-align: left;\">AE</td><td style = \"text-align: right;\">34</td><td style = \"text-align: left;\">-7.1\\n141</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">23</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">105.8</td><td style = \"text-align: right;\">191</td><td style = \"text-align: right;\">105.4</td><td style = \"text-align: right;\">150</td><td style = \"text-align: right;\">0.5109</td><td style = \"text-align: right;\">153</td><td style = \"text-align: right;\">51.0</td><td style = \"text-align: right;\">162</td><td style = \"text-align: right;\">47.7</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">16.5</td><td style = \"text-align: right;\">132</td><td style = \"text-align: right;\">16.4</td><td style = \"text-align: right;\">228</td><td style = \"text-align: right;\">34.2</td><td style = \"text-align: right;\">54</td><td style = \"text-align: right;\">28.8</td><td style = \"text-align: right;\">126</td><td style = \"text-align: right;\">30.4</td><td style = \"text-align: right;\">260</td><td style = \"text-align: right;\">30.0</td><td style = \"text-align: right;\">100</td><td style = \"text-align: right;\">51.5</td><td style = \"text-align: right;\">153</td><td style = \"text-align: right;\">47.3</td><td style = \"text-align: right;\">44</td><td style = \"text-align: right;\">33.4</td><td style = \"text-align: right;\">195</td><td style = \"text-align: right;\">32.2</td><td style = \"text-align: right;\">83</td><td style = \"text-align: right;\">34.8</td><td style = \"text-align: right;\">283</td><td style = \"text-align: right;\">36.0</td><td style = \"text-align: right;\">87</td><td style = \"text-align: right;\">72.4</td><td style = \"text-align: right;\">7</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">20</td><td style = \"text-align: left;\">Clemson</td><td style = \"text-align: left;\">ACC</td><td style = \"text-align: right;\">33</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">118.4</td><td style = \"text-align: right;\">26</td><td style = \"text-align: right;\">94.9</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">0.9272</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">53.6</td><td style = \"text-align: right;\">63</td><td style = \"text-align: right;\">48.9</td><td style = \"text-align: right;\">86</td><td style = \"text-align: right;\">15.7</td><td style = \"text-align: right;\">75</td><td style = \"text-align: right;\">20.1</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">33.7</td><td style = \"text-align: right;\">65</td><td style = \"text-align: right;\">29.9</td><td style = \"text-align: right;\">185</td><td style = \"text-align: right;\">28.2</td><td style = \"text-align: right;\">314</td><td style = \"text-align: right;\">27.6</td><td style = \"text-align: right;\">46</td><td style = \"text-align: right;\">52.3</td><td style = \"text-align: right;\">129</td><td style = \"text-align: right;\">49.3</td><td style = \"text-align: right;\">114</td><td style = \"text-align: right;\">37.2</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">32.2</td><td style = \"text-align: right;\">83</td><td style = \"text-align: right;\">38.4</td><td style = \"text-align: right;\">182</td><td style = \"text-align: right;\">38.3</td><td style = \"text-align: right;\">158</td><td style = \"text-align: right;\">64.3</td><td style = \"text-align: right;\">329</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">39</td><td style = \"text-align: left;\">Colorado St.</td><td style = \"text-align: left;\">MWC</td><td style = \"text-align: right;\">34</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">25</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">116.7</td><td style = \"text-align: right;\">40</td><td style = \"text-align: right;\">98.9</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">0.8698</td><td style = \"text-align: right;\">39</td><td style = \"text-align: right;\">55.8</td><td style = \"text-align: right;\">24</td><td style = \"text-align: right;\">48.5</td><td style = \"text-align: right;\">68</td><td style = \"text-align: right;\">17.4</td><td style = \"text-align: right;\">192</td><td style = \"text-align: right;\">16.7</td><td style = \"text-align: right;\">200</td><td style = \"text-align: right;\">26.4</td><td style = \"text-align: right;\">278</td><td style = \"text-align: right;\">25.3</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">31.8</td><td style = \"text-align: right;\">206</td><td style = \"text-align: right;\">33.6</td><td style = \"text-align: right;\">198</td><td style = \"text-align: right;\">56.5</td><td style = \"text-align: right;\">25</td><td style = \"text-align: right;\">47.7</td><td style = \"text-align: right;\">56</td><td style = \"text-align: right;\">36.6</td><td style = \"text-align: right;\">46</td><td style = \"text-align: right;\">33.1</td><td style = \"text-align: right;\">127</td><td style = \"text-align: right;\">42.8</td><td style = \"text-align: right;\">85</td><td style = \"text-align: right;\">37.9</td><td style = \"text-align: right;\">142</td><td style = \"text-align: right;\">66.1</td><td style = \"text-align: right;\">244</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">36</td><td style = \"text-align: left;\">Connecticut</td><td style = \"text-align: left;\">BE</td><td style = \"text-align: right;\">33</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">23</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">121.6</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">102.1</td><td style = \"text-align: right;\">93</td><td style = \"text-align: right;\">0.8817</td><td style = \"text-align: right;\">36</td><td style = \"text-align: right;\">55.5</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">48.3</td><td style = \"text-align: right;\">60</td><td style = \"text-align: right;\">17.1</td><td style = \"text-align: right;\">174</td><td style = \"text-align: right;\">15.5</td><td style = \"text-align: right;\">287</td><td style = \"text-align: right;\">35.6</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">27.4</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">30.6</td><td style = \"text-align: right;\">255</td><td style = \"text-align: right;\">40.0</td><td style = \"text-align: right;\">332</td><td style = \"text-align: right;\">57.3</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">46.0</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">35.4</td><td style = \"text-align: right;\">88</td><td style = \"text-align: right;\">35.1</td><td style = \"text-align: right;\">256</td><td style = \"text-align: right;\">42.6</td><td style = \"text-align: right;\">90</td><td style = \"text-align: right;\">34.2</td><td style = \"text-align: right;\">35</td><td style = \"text-align: right;\">63.9</td><td style = \"text-align: right;\">340</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">57</td><td style = \"text-align: right;\">7</td><td style = \"text-align: left;\">Texas Tech</td><td style = \"text-align: left;\">B12</td><td style = \"text-align: right;\">33</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">25</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">126.0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">96.9</td><td style = \"text-align: right;\">32</td><td style = \"text-align: right;\">0.9539</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">55.5</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">48.0</td><td style = \"text-align: right;\">53</td><td style = \"text-align: right;\">14.8</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">17.4</td><td style = \"text-align: right;\">155</td><td style = \"text-align: right;\">34.3</td><td style = \"text-align: right;\">51</td><td style = \"text-align: right;\">28.5</td><td style = \"text-align: right;\">107</td><td style = \"text-align: right;\">29.7</td><td style = \"text-align: right;\">280</td><td style = \"text-align: right;\">33.5</td><td style = \"text-align: right;\">196</td><td style = \"text-align: right;\">54.3</td><td style = \"text-align: right;\">63</td><td style = \"text-align: right;\">48.2</td><td style = \"text-align: right;\">68</td><td style = \"text-align: right;\">37.9</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">31.7</td><td style = \"text-align: right;\">61</td><td style = \"text-align: right;\">44.6</td><td style = \"text-align: right;\">60</td><td style = \"text-align: right;\">34.1</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">65.6</td><td style = \"text-align: right;\">273</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">58</td><td style = \"text-align: right;\">101</td><td style = \"text-align: left;\">Troy</td><td style = \"text-align: left;\">SB</td><td style = \"text-align: right;\">33</td><td style = \"text-align: left;\">-4.3\\n94</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">23</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">106.9</td><td style = \"text-align: right;\">161</td><td style = \"text-align: right;\">100.5</td><td style = \"text-align: right;\">70</td><td style = \"text-align: right;\">0.6702</td><td style = \"text-align: right;\">101</td><td style = \"text-align: right;\">50.1</td><td style = \"text-align: right;\">214</td><td style = \"text-align: right;\">47.2</td><td style = \"text-align: right;\">29</td><td style = \"text-align: right;\">19.9</td><td style = \"text-align: right;\">330</td><td style = \"text-align: right;\">19.8</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">38.6</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">32.0</td><td style = \"text-align: right;\">287</td><td style = \"text-align: right;\">37.8</td><td style = \"text-align: right;\">47</td><td style = \"text-align: right;\">29.3</td><td style = \"text-align: right;\">82</td><td style = \"text-align: right;\">53.9</td><td style = \"text-align: right;\">72</td><td style = \"text-align: right;\">46.2</td><td style = \"text-align: right;\">19</td><td style = \"text-align: right;\">30.3</td><td style = \"text-align: right;\">339</td><td style = \"text-align: right;\">32.6</td><td style = \"text-align: right;\">101</td><td style = \"text-align: right;\">44.8</td><td style = \"text-align: right;\">57</td><td style = \"text-align: right;\">38.1</td><td style = \"text-align: right;\">153</td><td style = \"text-align: right;\">66.2</td><td style = \"text-align: right;\">237</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">59</td><td style = \"text-align: right;\">48</td><td style = \"text-align: left;\">UC San Diego</td><td style = \"text-align: left;\">BW</td><td style = \"text-align: right;\">34</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">113.3</td><td style = \"text-align: right;\">67</td><td style = \"text-align: right;\">97.3</td><td style = \"text-align: right;\">36</td><td style = \"text-align: right;\">0.8519</td><td style = \"text-align: right;\">48</td><td style = \"text-align: right;\">55.4</td><td style = \"text-align: right;\">31</td><td style = \"text-align: right;\">47.7</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">13.4</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">23.3</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">25.6</td><td style = \"text-align: right;\">306</td><td style = \"text-align: right;\">28.4</td><td style = \"text-align: right;\">102</td><td style = \"text-align: right;\">33.8</td><td style = \"text-align: right;\">152</td><td style = \"text-align: right;\">29.8</td><td style = \"text-align: right;\">93</td><td style = \"text-align: right;\">56.1</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">46.2</td><td style = \"text-align: right;\">19</td><td style = \"text-align: right;\">36.5</td><td style = \"text-align: right;\">53</td><td style = \"text-align: right;\">33.1</td><td style = \"text-align: right;\">127</td><td style = \"text-align: right;\">49.6</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">44.3</td><td style = \"text-align: right;\">328</td><td style = \"text-align: right;\">65.9</td><td style = \"text-align: right;\">264</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">60</td><td style = \"text-align: right;\">25</td><td style = \"text-align: left;\">UCLA</td><td style = \"text-align: left;\">B10</td><td style = \"text-align: right;\">32</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">117.9</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">95.4</td><td style = \"text-align: right;\">19</td><td style = \"text-align: right;\">0.9199</td><td style = \"text-align: right;\">25</td><td style = \"text-align: right;\">53.0</td><td style = \"text-align: right;\">80</td><td style = \"text-align: right;\">50.5</td><td style = \"text-align: right;\">156</td><td style = \"text-align: right;\">15.9</td><td style = \"text-align: right;\">88</td><td style = \"text-align: right;\">22.8</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">32.8</td><td style = \"text-align: right;\">90</td><td style = \"text-align: right;\">29.2</td><td style = \"text-align: right;\">149</td><td style = \"text-align: right;\">32.9</td><td style = \"text-align: right;\">180</td><td style = \"text-align: right;\">34.6</td><td style = \"text-align: right;\">220</td><td style = \"text-align: right;\">53.1</td><td style = \"text-align: right;\">102</td><td style = \"text-align: right;\">51.2</td><td style = \"text-align: right;\">189</td><td style = \"text-align: right;\">35.2</td><td style = \"text-align: right;\">96</td><td style = \"text-align: right;\">33.2</td><td style = \"text-align: right;\">130</td><td style = \"text-align: right;\">36.0</td><td style = \"text-align: right;\">257</td><td style = \"text-align: right;\">44.8</td><td style = \"text-align: right;\">337</td><td style = \"text-align: right;\">65.1</td><td style = \"text-align: right;\">295</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">61</td><td style = \"text-align: right;\">108</td><td style = \"text-align: left;\">UNC Wilmington</td><td style = \"text-align: left;\">CAA</td><td style = \"text-align: right;\">34</td><td style = \"text-align: left;\">-3.2\\n80</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">112.4</td><td style = \"text-align: right;\">76</td><td style = \"text-align: right;\">106.9</td><td style = \"text-align: right;\">185</td><td style = \"text-align: right;\">0.6409</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">52.2</td><td style = \"text-align: right;\">105</td><td style = \"text-align: right;\">50.9</td><td style = \"text-align: right;\">178</td><td style = \"text-align: right;\">16.0</td><td style = \"text-align: right;\">95</td><td style = \"text-align: right;\">17.4</td><td style = \"text-align: right;\">155</td><td style = \"text-align: right;\">35.4</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">28.1</td><td style = \"text-align: right;\">89</td><td style = \"text-align: right;\">37.8</td><td style = \"text-align: right;\">47</td><td style = \"text-align: right;\">30.3</td><td style = \"text-align: right;\">110</td><td style = \"text-align: right;\">53.8</td><td style = \"text-align: right;\">78</td><td style = \"text-align: right;\">50.4</td><td style = \"text-align: right;\">153</td><td style = \"text-align: right;\">33.0</td><td style = \"text-align: right;\">212</td><td style = \"text-align: right;\">34.4</td><td style = \"text-align: right;\">214</td><td style = \"text-align: right;\">36.2</td><td style = \"text-align: right;\">252</td><td style = \"text-align: right;\">42.6</td><td style = \"text-align: right;\">297</td><td style = \"text-align: right;\">65.2</td><td style = \"text-align: right;\">291</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">62</td><td style = \"text-align: right;\">50</td><td style = \"text-align: left;\">Utah St.</td><td style = \"text-align: left;\">MWC</td><td style = \"text-align: right;\">33</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">26</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">122.4</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">105.5</td><td style = \"text-align: right;\">153</td><td style = \"text-align: right;\">0.8458</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">56.0</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">51.8</td><td style = \"text-align: right;\">231</td><td style = \"text-align: right;\">16.0</td><td style = \"text-align: right;\">95</td><td style = \"text-align: right;\">20.2</td><td style = \"text-align: right;\">37</td><td style = \"text-align: right;\">34.6</td><td style = \"text-align: right;\">43</td><td style = \"text-align: right;\">30.3</td><td style = \"text-align: right;\">211</td><td style = \"text-align: right;\">37.6</td><td style = \"text-align: right;\">52</td><td style = \"text-align: right;\">36.2</td><td style = \"text-align: right;\">265</td><td style = \"text-align: right;\">57.7</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">52.6</td><td style = \"text-align: right;\">250</td><td style = \"text-align: right;\">35.8</td><td style = \"text-align: right;\">68</td><td style = \"text-align: right;\">33.8</td><td style = \"text-align: right;\">177</td><td style = \"text-align: right;\">42.3</td><td style = \"text-align: right;\">93</td><td style = \"text-align: right;\">44.4</td><td style = \"text-align: right;\">329</td><td style = \"text-align: right;\">67.7</td><td style = \"text-align: right;\">153</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">63</td><td style = \"text-align: right;\">31</td><td style = \"text-align: left;\">VCU</td><td style = \"text-align: left;\">A10</td><td style = \"text-align: right;\">34</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">116.1</td><td style = \"text-align: right;\">44</td><td style = \"text-align: right;\">96.3</td><td style = \"text-align: right;\">26</td><td style = \"text-align: right;\">0.8961</td><td style = \"text-align: right;\">31</td><td style = \"text-align: right;\">52.4</td><td style = \"text-align: right;\">98</td><td style = \"text-align: right;\">44.4</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">16.8</td><td style = \"text-align: right;\">155</td><td style = \"text-align: right;\">20.6</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">36.7</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">30.0</td><td style = \"text-align: right;\">193</td><td style = \"text-align: right;\">32.2</td><td style = \"text-align: right;\">198</td><td style = \"text-align: right;\">36.1</td><td style = \"text-align: right;\">263</td><td style = \"text-align: right;\">54.2</td><td style = \"text-align: right;\">65</td><td style = \"text-align: right;\">43.6</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">33.5</td><td style = \"text-align: right;\">190</td><td style = \"text-align: right;\">30.6</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">47.4</td><td style = \"text-align: right;\">25</td><td style = \"text-align: right;\">35.3</td><td style = \"text-align: right;\">63</td><td style = \"text-align: right;\">66.2</td><td style = \"text-align: right;\">238</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">64</td><td style = \"text-align: right;\">41</td><td style = \"text-align: left;\">Vanderbilt</td><td style = \"text-align: left;\">SEC</td><td style = \"text-align: right;\">32</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">118.8</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">101.3</td><td style = \"text-align: right;\">83</td><td style = \"text-align: right;\">0.8616</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">51.7</td><td style = \"text-align: right;\">122</td><td style = \"text-align: right;\">52.9</td><td style = \"text-align: right;\">275</td><td style = \"text-align: right;\">14.7</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">20.0</td><td style = \"text-align: right;\">43</td><td style = \"text-align: right;\">32.2</td><td style = \"text-align: right;\">107</td><td style = \"text-align: right;\">29.7</td><td style = \"text-align: right;\">175</td><td style = \"text-align: right;\">34.0</td><td style = \"text-align: right;\">148</td><td style = \"text-align: right;\">39.0</td><td style = \"text-align: right;\">311</td><td style = \"text-align: right;\">53.6</td><td style = \"text-align: right;\">85</td><td style = \"text-align: right;\">51.5</td><td style = \"text-align: right;\">204</td><td style = \"text-align: right;\">32.5</td><td style = \"text-align: right;\">239</td><td style = \"text-align: right;\">36.9</td><td style = \"text-align: right;\">337</td><td style = \"text-align: right;\">40.2</td><td style = \"text-align: right;\">146</td><td style = \"text-align: right;\">37.5</td><td style = \"text-align: right;\">125</td><td style = \"text-align: right;\">69.6</td><td style = \"text-align: right;\">60</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">65</td><td style = \"text-align: right;\">12</td><td style = \"text-align: left;\">Wisconsin</td><td style = \"text-align: left;\">B10</td><td style = \"text-align: right;\">35</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">26</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">122.5</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">96.3</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">0.941</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">53.6</td><td style = \"text-align: right;\">63</td><td style = \"text-align: right;\">47.9</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">14.1</td><td style = \"text-align: right;\">17</td><td style = \"text-align: right;\">14.5</td><td style = \"text-align: right;\">331</td><td style = \"text-align: right;\">28.0</td><td style = \"text-align: right;\">237</td><td style = \"text-align: right;\">26.6</td><td style = \"text-align: right;\">41</td><td style = \"text-align: right;\">33.8</td><td style = \"text-align: right;\">152</td><td style = \"text-align: right;\">28.1</td><td style = \"text-align: right;\">56</td><td style = \"text-align: right;\">54.7</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">46.8</td><td style = \"text-align: right;\">31</td><td style = \"text-align: right;\">34.9</td><td style = \"text-align: right;\">116</td><td style = \"text-align: right;\">33.0</td><td style = \"text-align: right;\">123</td><td style = \"text-align: right;\">48.1</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">39.1</td><td style = \"text-align: right;\">189</td><td style = \"text-align: right;\">67.5</td><td style = \"text-align: right;\">163</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">66</td><td style = \"text-align: right;\">143</td><td style = \"text-align: left;\">Wofford</td><td style = \"text-align: left;\">SC</td><td style = \"text-align: right;\">34</td><td style = \"text-align: left;\">-9.7\\n193</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">19</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">111.6</td><td style = \"text-align: right;\">90</td><td style = \"text-align: right;\">109.7</td><td style = \"text-align: right;\">246</td><td style = \"text-align: right;\">0.549</td><td style = \"text-align: right;\">143</td><td style = \"text-align: right;\">53.3</td><td style = \"text-align: right;\">73</td><td style = \"text-align: right;\">51.8</td><td style = \"text-align: right;\">231</td><td style = \"text-align: right;\">16.9</td><td style = \"text-align: right;\">160</td><td style = \"text-align: right;\">14.9</td><td style = \"text-align: right;\">319</td><td style = \"text-align: right;\">35.5</td><td style = \"text-align: right;\">26</td><td style = \"text-align: right;\">26.2</td><td style = \"text-align: right;\">32</td><td style = \"text-align: right;\">31.1</td><td style = \"text-align: right;\">234</td><td style = \"text-align: right;\">36.2</td><td style = \"text-align: right;\">265</td><td style = \"text-align: right;\">54.6</td><td style = \"text-align: right;\">53</td><td style = \"text-align: right;\">51.8</td><td style = \"text-align: right;\">216</td><td style = \"text-align: right;\">34.5</td><td style = \"text-align: right;\">138</td><td style = \"text-align: right;\">34.5</td><td style = \"text-align: right;\">222</td><td style = \"text-align: right;\">47.7</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">45.8</td><td style = \"text-align: right;\">344</td><td style = \"text-align: right;\">64.0</td><td style = \"text-align: right;\">335</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">67</td><td style = \"text-align: right;\">37</td><td style = \"text-align: left;\">Xavier</td><td style = \"text-align: left;\">BE</td><td style = \"text-align: right;\">32</td><td style = \"text-align: left;\">#ERROR!</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">21</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">116.3</td><td style = \"text-align: right;\">42</td><td style = \"text-align: right;\">97.9</td><td style = \"text-align: right;\">38</td><td style = \"text-align: right;\">0.8788</td><td style = \"text-align: right;\">37</td><td style = \"text-align: right;\">53.9</td><td style = \"text-align: right;\">55</td><td style = \"text-align: right;\">50.6</td><td style = \"text-align: right;\">163</td><td style = \"text-align: right;\">16.0</td><td style = \"text-align: right;\">95</td><td style = \"text-align: right;\">17.6</td><td style = \"text-align: right;\">139</td><td style = \"text-align: right;\">25.2</td><td style = \"text-align: right;\">315</td><td style = \"text-align: right;\">25.2</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">37.2</td><td style = \"text-align: right;\">60</td><td style = \"text-align: right;\">28.1</td><td style = \"text-align: right;\">56</td><td style = \"text-align: right;\">51.3</td><td style = \"text-align: right;\">164</td><td style = \"text-align: right;\">50.5</td><td style = \"text-align: right;\">157</td><td style = \"text-align: right;\">38.8</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">33.9</td><td style = \"text-align: right;\">187</td><td style = \"text-align: right;\">37.4</td><td style = \"text-align: right;\">213</td><td style = \"text-align: right;\">37.2</td><td style = \"text-align: right;\">118</td><td style = \"text-align: right;\">69.1</td><td style = \"text-align: right;\">78</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">68</td><td style = \"text-align: right;\">78</td><td style = \"text-align: left;\">Yale</td><td style = \"text-align: left;\">Ivy</td><td style = \"text-align: right;\">29</td><td style = \"text-align: left;\">-2.7\\n73</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">2025</td><td style = \"text-align: right;\">114.0</td><td style = \"text-align: right;\">61</td><td style = \"text-align: right;\">103.8</td><td style = \"text-align: right;\">116</td><td style = \"text-align: right;\">0.7457</td><td style = \"text-align: right;\">78</td><td style = \"text-align: right;\">54.8</td><td style = \"text-align: right;\">40</td><td style = \"text-align: right;\">48.8</td><td style = \"text-align: right;\">80</td><td style = \"text-align: right;\">14.4</td><td style = \"text-align: right;\">19</td><td style = \"text-align: right;\">16.1</td><td style = \"text-align: right;\">249</td><td style = \"text-align: right;\">33.2</td><td style = \"text-align: right;\">79</td><td style = \"text-align: right;\">25.8</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">32.0</td><td style = \"text-align: right;\">204</td><td style = \"text-align: right;\">28.7</td><td style = \"text-align: right;\">71</td><td style = \"text-align: right;\">53.4</td><td style = \"text-align: right;\">89</td><td style = \"text-align: right;\">47.3</td><td style = \"text-align: right;\">44</td><td style = \"text-align: right;\">38.5</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">33.7</td><td style = \"text-align: right;\">170</td><td style = \"text-align: right;\">32.0</td><td style = \"text-align: right;\">336</td><td style = \"text-align: right;\">48.0</td><td style = \"text-align: right;\">359</td><td style = \"text-align: right;\">67.3</td><td style = \"text-align: right;\">180</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& RK & TEAM & CONF & G & WAB & POSTSEASON & SEED & WINS & LOSSES & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String31 & String7 & Int64 & String15 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 95 & Akron & MAC & 34 & -1.7\\textbackslash{}n63 & 0 & 13 & 28 & 6 & $\\dots$ \\\\\n",
       "\t2 & 5 & Alabama & SEC & 33 & \\#ERROR! & 0 & 2 & 25 & 8 & $\\dots$ \\\\\n",
       "\t3 & 275 & Alabama St. & SWAC & 35 & -10.1\\textbackslash{}n200 & 0 & 16 & 20 & 15 & $\\dots$ \\\\\n",
       "\t4 & 243 & American & Pat & 34 & -8.2\\textbackslash{}n165 & 0 & 16 & 22 & 12 & $\\dots$ \\\\\n",
       "\t5 & 9 & Arizona & B12 & 34 & \\#ERROR! & 0 & 4 & 22 & 12 & $\\dots$ \\\\\n",
       "\t6 & 42 & Arkansas & SEC & 33 & \\#ERROR! & 0 & 10 & 20 & 13 & $\\dots$ \\\\\n",
       "\t7 & 3 & Auburn & SEC & 33 & \\#ERROR! & 0 & 1 & 28 & 5 & $\\dots$ \\\\\n",
       "\t8 & 14 & BYU & B12 & 33 & \\#ERROR! & 0 & 6 & 24 & 9 & $\\dots$ \\\\\n",
       "\t9 & 27 & Baylor & B12 & 33 & \\#ERROR! & 0 & 9 & 19 & 14 & $\\dots$ \\\\\n",
       "\t10 & 153 & Bryant & AE & 34 & -7.1\\textbackslash{}n141 & 0 & 15 & 23 & 11 & $\\dots$ \\\\\n",
       "\t11 & 20 & Clemson & ACC & 33 & \\#ERROR! & 0 & 5 & 27 & 6 & $\\dots$ \\\\\n",
       "\t12 & 39 & Colorado St. & MWC & 34 & \\#ERROR! & 0 & 12 & 25 & 9 & $\\dots$ \\\\\n",
       "\t13 & 36 & Connecticut & BE & 33 & \\#ERROR! & 0 & 8 & 23 & 10 & $\\dots$ \\\\\n",
       "\t14 & 34 & Creighton & BE & 34 & \\#ERROR! & 0 & 9 & 24 & 10 & $\\dots$ \\\\\n",
       "\t15 & 56 & Drake & MVC & 33 & \\#ERROR! & 0 & 11 & 30 & 3 & $\\dots$ \\\\\n",
       "\t16 & 2 & Duke & ACC & 34 & \\#ERROR! & 0 & 1 & 31 & 3 & $\\dots$ \\\\\n",
       "\t17 & 4 & Florida & SEC & 34 & \\#ERROR! & 0 & 1 & 30 & 4 & $\\dots$ \\\\\n",
       "\t18 & 28 & Georgia & SEC & 32 & \\#ERROR! & 0 & 9 & 20 & 12 & $\\dots$ \\\\\n",
       "\t19 & 11 & Gonzaga & WCC & 33 & \\#ERROR! & 0 & 8 & 25 & 8 & $\\dots$ \\\\\n",
       "\t20 & 83 & Grand Canyon & WAC & 33 & -2.5\\textbackslash{}n70 & 0 & 13 & 26 & 7 & $\\dots$ \\\\\n",
       "\t21 & 85 & High Point & BSth & 34 & -1.8\\textbackslash{}n65 & 0 & 13 & 29 & 5 & $\\dots$ \\\\\n",
       "\t22 & 1 & Houston & B12 & 34 & \\#ERROR! & 0 & 1 & 30 & 4 & $\\dots$ \\\\\n",
       "\t23 & 23 & Illinois & B10 & 33 & \\#ERROR! & 0 & 6 & 21 & 12 & $\\dots$ \\\\\n",
       "\t24 & 8 & Iowa St. & B12 & 33 & \\#ERROR! & 0 & 3 & 24 & 9 & $\\dots$ \\\\\n",
       "\t25 & 21 & Kansas & B12 & 33 & \\#ERROR! & 0 & 7 & 21 & 12 & $\\dots$ \\\\\n",
       "\t26 & 17 & Kentucky & SEC & 33 & \\#ERROR! & 0 & 3 & 22 & 11 & $\\dots$ \\\\\n",
       "\t27 & 54 & Liberty & CUSA & 34 & -0.12\\textbackslash{}n54 & 0 & 12 & 28 & 6 & $\\dots$ \\\\\n",
       "\t28 & 98 & Lipscomb & ASun & 34 & -4.1\\textbackslash{}n90 & 0 & 14 & 25 & 9 & $\\dots$ \\\\\n",
       "\t29 & 18 & Louisville & ACC & 34 & \\#ERROR! & 0 & 8 & 27 & 7 & $\\dots$ \\\\\n",
       "\t30 & 30 & Marquette & BE & 33 & \\#ERROR! & 0 & 7 & 23 & 10 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m68Ã—46 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0mâ”‚\u001b[1m RK    \u001b[0m\u001b[1m TEAM           \u001b[0m\u001b[1m CONF    \u001b[0m\u001b[1m G     \u001b[0m\u001b[1m WAB        \u001b[0m\u001b[1m POSTSEASON \u001b[0m\u001b[1m SEED  \u001b[0m\u001b[1m W\u001b[0m â‹¯\n",
       "     â”‚\u001b[90m Int64 \u001b[0m\u001b[90m String31       \u001b[0m\u001b[90m String7 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m String15   \u001b[0m\u001b[90m Int64      \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m I\u001b[0m â‹¯\n",
       "â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "   1 â”‚    95  Akron           MAC         34  -1.7\\n63             0     13    â‹¯\n",
       "   2 â”‚     5  Alabama         SEC         33  #ERROR!              0      2\n",
       "   3 â”‚   275  Alabama St.     SWAC        35  -10.1\\n200           0     16\n",
       "   4 â”‚   243  American        Pat         34  -8.2\\n165            0     16\n",
       "   5 â”‚     9  Arizona         B12         34  #ERROR!              0      4    â‹¯\n",
       "   6 â”‚    42  Arkansas        SEC         33  #ERROR!              0     10\n",
       "   7 â”‚     3  Auburn          SEC         33  #ERROR!              0      1\n",
       "   8 â”‚    14  BYU             B12         33  #ERROR!              0      6\n",
       "   9 â”‚    27  Baylor          B12         33  #ERROR!              0      9    â‹¯\n",
       "  10 â”‚   153  Bryant          AE          34  -7.1\\n141            0     15\n",
       "  11 â”‚    20  Clemson         ACC         33  #ERROR!              0      5\n",
       "  â‹®  â”‚   â‹®          â‹®            â‹®       â‹®        â‹®           â‹®         â‹®      â‹±\n",
       "  59 â”‚    48  UC San Diego    BW          34  #ERROR!              0     12\n",
       "  60 â”‚    25  UCLA            B10         32  #ERROR!              0      7    â‹¯\n",
       "  61 â”‚   108  UNC Wilmington  CAA         34  -3.2\\n80             0     14\n",
       "  62 â”‚    50  Utah St.        MWC         33  #ERROR!              0     10\n",
       "  63 â”‚    31  VCU             A10         34  #ERROR!              0     11\n",
       "  64 â”‚    41  Vanderbilt      SEC         32  #ERROR!              0     10    â‹¯\n",
       "  65 â”‚    12  Wisconsin       B10         35  #ERROR!              0      3\n",
       "  66 â”‚   143  Wofford         SC          34  -9.7\\n193            0     15\n",
       "  67 â”‚    37  Xavier          BE          32  #ERROR!              0     11\n",
       "  68 â”‚    78  Yale            Ivy         29  -2.7\\n73             0     13    â‹¯\n",
       "\u001b[36m                                                  39 columns and 47 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV, DataFrames\n",
    "\n",
    "filepath = \"/mnt/chromeos/removable/memexpand/basketball_data/tournament_teams_by_round/cbb08_24_tourn_all.csv\"\n",
    "df = CSV.read(filepath, DataFrame)\n",
    "filepath_test = \"/mnt/chromeos/removable/memexpand/basketball_data/clean data all teams/cbb2025.csv\"\n",
    "df_test = CSV.read(filepath_test, DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current features\n",
    "\n",
    "selected_columns = [\n",
    "    \"BARTHAG\",\n",
    "    #\"WINS\",\n",
    "    \"SEED\",\n",
    "    \"ADJOE\",\n",
    "    \"ADJDE\",\n",
    "    \"2P%\",  # Assuming 2P% is stored as 2P_O in your dataset\n",
    "    \"3P%\",  # Assuming 3P% is stored as 3P_O in your dataset\n",
    "    #\"EFG%\", # Assuming EFG% is stored as EFG_O in your dataset\n",
    "    #\"FTR\",\n",
    "    #\"TORD\"\n",
    "    \"POSTSEASON\"\n",
    "]\n",
    "\n",
    "selected_columns_a = [\n",
    "    \"BARTHAG\",\n",
    "    #\"WINS\",\n",
    "    \"SEED\",\n",
    "    \"ADJOE\",\n",
    "    \"ADJDE\",\n",
    "    \"2P%\",  # Assuming 2P% is stored as 2P_O in your dataset\n",
    "    \"3P%\",  # Assuming 3P% is stored as 3P_O in your dataset\n",
    "    #\"EFG%\", # Assuming EFG% is stored as EFG_O in your dataset\n",
    "    #\"FTR\",\n",
    "    #\"TORD\"\n",
    "    \"TEAM\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Vector{String}:\n",
       " \"SEED\"\n",
       " \"ADJOE_rank\"\n",
       " \"ADJDE_rank\"\n",
       " \"BARTHAG_rank\"\n",
       " \"EFG%_rank\"\n",
       " \"EFGD%_rank\"\n",
       " \"TOR_rank\"\n",
       " \"TORD_rank\"\n",
       " \"ORB_rank\"\n",
       " \"DRB_rank\"\n",
       " \"TEAM\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = [\"SEED\",\"ADJOE_rank\", \"ADJDE_rank\", \"BARTHAG_rank\", \"EFG%_rank\", \"EFGD%_rank\", \"TOR_rank\", \"TORD_rank\",\"ORB_rank\",\"DRB_rank\",\"POSTSEASON\"]\n",
    "\n",
    "selected_columns_a = [\"SEED\",\"ADJOE_rank\", \"ADJDE_rank\", \"BARTHAG_rank\", \"EFG%_rank\", \"EFGD%_rank\", \"TOR_rank\", \"TORD_rank\",\"ORB_rank\",\"DRB_rank\", \"TEAM\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (1011, 11)\n",
      "Testing set size: (68, 11)\n"
     ]
    }
   ],
   "source": [
    "using CSV, DataFrames\n",
    "\n",
    "# Split into training (2008-2023) and testing (2024) dataframes\n",
    "df_train = df[df.YEAR .!= 2024, Cols(vcat(\"YEAR\", selected_columns))]\n",
    "#df_test = df[df.YEAR .== 2024, Cols(vcat(\"YEAR\", selected_columns_a))]\n",
    "select!(df_test, selected_columns_a)\n",
    "\n",
    "\n",
    "# Remove specific columns from the training set if needed\n",
    "# df_train = select!(df_train, Not(:WAB, :TEAM, :CONF, :G))\n",
    "df_train = select!(df_train, Not(:YEAR))\n",
    "#df_test = select!(df_test, Not(:YEAR))\n",
    "#run the whole dataframe\n",
    "#df_train = df[df.YEAR .!= 2024, Not([:WAB, :TEAM, :CONF, :G])]\n",
    "#df_test = df[df.YEAR .== 2024, Not([:WAB, :TEAM, :CONF, :G])]\n",
    "\n",
    "# Print the sizes of the resulting dataframes\n",
    "println(\"Training set size: \", size(df_train))\n",
    "println(\"Testing set size: \", size(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size: (1011, 10)\n",
      "y length: 1011\n",
      "Original class distribution:\n",
      "Class 1: 531 samples\n",
      "Class 2: 240 samples\n",
      "Class 3: 120 samples\n",
      "Class 4: 60 samples\n",
      "Class 5: 30 samples\n",
      "Class 6: 15 samples\n",
      "Class 7: 15 samples\n"
     ]
    }
   ],
   "source": [
    "using DataFrames\n",
    "using MLJ\n",
    "using MLJBase: transform\n",
    "\n",
    "# Check if \"POSTSEASON\" exists in df_train\n",
    "if \"POSTSEASON\" in names(df_train)\n",
    "    y = df_train.POSTSEASON\n",
    "else\n",
    "    println(\"Column 'POSTSEASON' does not exist in df_train.\")\n",
    "    # Handle the case where \"POSTSEASON\" is not present\n",
    "    # For example, you might need to create or load it from another source\n",
    "end\n",
    "\n",
    "# Remove \"POSTSEASON\" from selected_columns if it's present\n",
    "selected_columns_without_postseason = filter(col -> col != \"POSTSEASON\", selected_columns)\n",
    "\n",
    "# Select columns from df_train, excluding \"POSTSEASON\"\n",
    "X = select(df_train, selected_columns_without_postseason)\n",
    "\n",
    "println(\"X size: $(size(X))\")\n",
    "if \"POSTSEASON\" in names(df_train)\n",
    "    println(\"y length: $(length(y))\")\n",
    "end\n",
    "\n",
    "# Convert X to matrix\n",
    "# Define the feature set used for training and prediction\n",
    "selected_columns_B = [\"ADJOE_rank\", \"ADJDE_rank\", \"BARTHAG_rank\", \"EFG%_rank\", \"EFGD%_rank\", \"TOR_rank\", \"TORD_rank\",\"ORB_rank\",\"DRB_rank\"]\n",
    "\n",
    "# Ensure X_matrix contains exactly these columns in the correct order\n",
    "X_matrix = select(df_train, selected_columns_B)\n",
    "\n",
    "# Ensure y is a vector of integers if it exists\n",
    "if \"POSTSEASON\" in names(df_train)\n",
    "    y_vector = convert(Vector{Int64}, y)\n",
    "    \n",
    "    # Print class distribution\n",
    "    println(\"Original class distribution:\")\n",
    "    for class in sort(unique(y_vector))\n",
    "        count = sum(y_vector .== class)\n",
    "        println(\"Class $class: $count samples\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "balanced_oversampling (generic function with 1 method)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames\n",
    "using Random\n",
    "Random.seed!(42)\n",
    "\n",
    "function balanced_oversampling(X::Matrix, y::Vector, target_count::Int)\n",
    "    # Get unique classes\n",
    "    classes = sort(unique(y))\n",
    "    \n",
    "    # Initialize arrays to hold oversampled data\n",
    "    X_balanced = Matrix{Float64}(undef, 0, size(X, 2))\n",
    "    y_balanced = Int64[]\n",
    "    \n",
    "    # Process each class\n",
    "    for class in classes\n",
    "        # Get indices for this class\n",
    "        class_indices = findall(y .== class)\n",
    "        class_count = length(class_indices)\n",
    "        \n",
    "        # Extract class data\n",
    "        X_class = X[class_indices, :]\n",
    "        y_class = y[class_indices]\n",
    "        \n",
    "        # If class already has enough samples, just take them all\n",
    "        if class_count >= target_count\n",
    "            # Optionally downsample if class is much larger than target\n",
    "            if class_count > target_count\n",
    "                sample_indices = randperm(class_count)[1:target_count]\n",
    "                X_balanced = vcat(X_balanced, X_class[sample_indices, :])\n",
    "                append!(y_balanced, y_class[sample_indices])\n",
    "            else\n",
    "                X_balanced = vcat(X_balanced, X_class)\n",
    "                append!(y_balanced, y_class)\n",
    "            end\n",
    "        else\n",
    "            # Need to oversample\n",
    "            # Add all original samples\n",
    "            X_balanced = vcat(X_balanced, X_class)\n",
    "            append!(y_balanced, y_class)\n",
    "            \n",
    "            # Calculate how many more samples we need\n",
    "            samples_needed = target_count - class_count\n",
    "            \n",
    "            # Generate random indices with replacement\n",
    "            random_indices = rand(1:class_count, samples_needed)\n",
    "            \n",
    "            # Add the oversampled data\n",
    "            X_balanced = vcat(X_balanced, X_class[random_indices, :])\n",
    "            append!(y_balanced, y_class[random_indices])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return X_balanced, y_balanced\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68Ã—10 Matrix{Int64}:\n",
       " 13   62  182   95   31  110  137  174   76  136\n",
       "  2    4   28    5   14   50  149  348   39  149\n",
       " 16  282  247  275  325  163    4   86  228  225\n",
       " 16  268  194  243  119  242  155  139  335   62\n",
       "  4   10   30    9   83   73  108  212   19  107\n",
       " 10   82   21   42   88   60  132  151  245   97\n",
       "  1    1   12    3   26   10    6  155   51  211\n",
       "  6    7   53   14    7  163  207  174   76   30\n",
       "  9   17   56   27  135  196  103   81   22  250\n",
       " 15  191  150  153  162   42  132  228   54  126\n",
       "  5   26   16   20   63   86   75   41   65  185\n",
       " 12   40   50   39   24   68  192  200  278   16\n",
       "  8   16   93   36   28   60  174  287   22   62\n",
       "  â‹®                        â‹®                 \n",
       "  3    6   32    7   28   53   30  155   51  107\n",
       " 14  161   70  101  214   29  330   50    6  287\n",
       " 12   67   36   48   31   42    6    2  306  102\n",
       "  7   27   19   25   80  156   88    5   90  149\n",
       " 14   76  185  108  105  178   95  155   28   89\n",
       " 10   14  153   50   20  231   95   37   43  211\n",
       " 11   44   26   31   98    1  155   27   11  193\n",
       " 10   22   83   41  122  275   28   43  107  175\n",
       "  3   13   27   12   63   50   17  331  237   41\n",
       " 15   90  246  143   73  231  160  319   26   32\n",
       " 11   42   38   37   55  163   95  139  315   14\n",
       " 13   61  116   78   40   80   19  249   79   22"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_matrix = Matrix(X)\n",
    "df_test_copy = copy(df_test)\n",
    "\n",
    "X_test = select!(df_test_copy, Not(:TEAM))\n",
    "X_test_matrix = Matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After SMOTE oversampling:\n",
      "Class 1: 531 samples\n",
      "Class 2: 531 samples\n",
      "Class 3: 531 samples\n",
      "Class 4: 531 samples\n",
      "Class 5: 531 samples\n",
      "Class 6: 531 samples\n",
      "Class 7: 531 samples\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "X_balanced, y_balanced = balanced_oversampling(X_matrix, y_vector, 531)\n",
    "\n",
    "# Convert back to DataFrames if needed\n",
    "X_over_df = DataFrame(X_balanced, :auto)\n",
    "y_over_df = DataFrame(:POSTSEASON => y_balanced)\n",
    "\n",
    "# Print the new class distribution\n",
    "println(\"\\nAfter SMOTE oversampling:\")\n",
    "for class in sort(unique(y_balanced))\n",
    "    count = sum(y_balanced .== class)\n",
    "    println(\"Class $class: $count samples\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLJ\n",
    "import MLJ: fit!, predict, predict_mode, machine\n",
    "using XGBoost\n",
    "using MLJLIBSVMInterface\n",
    "using DecisionTree\n",
    "using Random\n",
    "Random.seed!(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_model (generic function with 1 method)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to evaluate each model individually\n",
    "function evaluate_model(model, model_name, X, y, train_indices, test_indices)\n",
    "    println(\"Evaluating $model_name...\")\n",
    "    model_machine = machine(model, X, y)\n",
    "    MLJ.fit!(model_machine, rows=train_indices)\n",
    "    y_pred = MLJ.predict_mode(model_machine, rows=test_indices)\n",
    "    acc = accuracy(y_pred, y[test_indices])\n",
    "    println(\"$model_name Accuracy: \", round(acc, digits=4))\n",
    "    return model_machine\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJXGBoostInterface âœ”\n",
      "import MLJDecisionTreeInterface âœ”\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJDecisionTreeInterface âœ”\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(\n",
       "  max_depth = -1, \n",
       "  min_samples_leaf = 1, \n",
       "  min_samples_split = 2, \n",
       "  min_purity_increase = 0.0, \n",
       "  n_subfeatures = 0, \n",
       "  post_prune = false, \n",
       "  merge_purity_threshold = 1.0, \n",
       "  display_depth = 5, \n",
       "  feature_importance = :impurity, \n",
       "  rng = TaskLocalRNG())"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load individual models\n",
    "XGBoost_model = @load XGBoostClassifier pkg=XGBoost\n",
    "forest_model = @load RandomForestClassifier pkg=DecisionTree\n",
    "d_tree_model = @load DecisionTreeClassifier pkg=DecisionTree\n",
    "\n",
    "# Define models with hyperparameters\n",
    "boosting_model = XGBoost_model(num_round=10, max_depth=3)\n",
    "forest_model = forest_model()\n",
    "d_tree_model = d_tree_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68Ã—10 Matrix{Int64}:\n",
       " 13   62  182   95   31  110  137  174   76  136\n",
       "  2    4   28    5   14   50  149  348   39  149\n",
       " 16  282  247  275  325  163    4   86  228  225\n",
       " 16  268  194  243  119  242  155  139  335   62\n",
       "  4   10   30    9   83   73  108  212   19  107\n",
       " 10   82   21   42   88   60  132  151  245   97\n",
       "  1    1   12    3   26   10    6  155   51  211\n",
       "  6    7   53   14    7  163  207  174   76   30\n",
       "  9   17   56   27  135  196  103   81   22  250\n",
       " 15  191  150  153  162   42  132  228   54  126\n",
       "  5   26   16   20   63   86   75   41   65  185\n",
       " 12   40   50   39   24   68  192  200  278   16\n",
       "  8   16   93   36   28   60  174  287   22   62\n",
       "  â‹®                        â‹®                 \n",
       "  3    6   32    7   28   53   30  155   51  107\n",
       " 14  161   70  101  214   29  330   50    6  287\n",
       " 12   67   36   48   31   42    6    2  306  102\n",
       "  7   27   19   25   80  156   88    5   90  149\n",
       " 14   76  185  108  105  178   95  155   28   89\n",
       " 10   14  153   50   20  231   95   37   43  211\n",
       " 11   44   26   31   98    1  155   27   11  193\n",
       " 10   22   83   41  122  275   28   43  107  175\n",
       "  3   13   27   12   63   50   17  331  237   41\n",
       " 15   90  246  143   73  231  160  319   26   32\n",
       " 11   42   38   37   55  163   95  139  315   14\n",
       " 13   61  116   78   40   80   19  249   79   22"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3178, 370, 1013, 979, 1101, 216, 331, 2301, 2455, 33  â€¦  2258, 2263, 1458, 71, 1896, 1773, 373, 2878, 70, 482], [3602, 2265, 332, 1923, 1843, 3702, 3061, 3133, 2607, 1568  â€¦  72, 3644, 2621, 2473, 662, 963, 3447, 3001, 2618, 1206])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data to tables if needed\n",
    "X_table = MLJ.table(X_balanced)\n",
    "y_cat = categorical(y_balanced)\n",
    "X_test_table = MLJ.table(X_matrix_test)\n",
    "\n",
    "# Create train/test split\n",
    "train, test = partition(eachindex(y_cat), 0.8, shuffle=true, rng=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_model (generic function with 1 method)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to evaluate each model individually\n",
    "function evaluate_model(model, model_name, X, y, train_indices, test_indices)\n",
    "    println(\"Evaluating $model_name...\")\n",
    "    model_machine = machine(model, X, y)\n",
    "    MLJ.fit!(model_machine, rows=train_indices)\n",
    "    y_pred = MLJ.predict_mode(model_machine, rows=test_indices)\n",
    "    acc = accuracy(y_pred, y[test_indices])\n",
    "    println(\"$model_name Accuracy: \", round(acc, digits=4))\n",
    "    return model_machine\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual model performances:\n",
      "Evaluating XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(XGBoostClassifier(test = 1, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mXGBoost: starting training.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[1]\ttrain-mlogloss:1.61594114078317785\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[2]\ttrain-mlogloss:1.44170167412866901\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[3]\ttrain-mlogloss:1.30709032945850989\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[4]\ttrain-mlogloss:1.20926078277180959\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[5]\ttrain-mlogloss:1.12804281678509222\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[6]\ttrain-mlogloss:1.07320544867204504\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[7]\ttrain-mlogloss:1.00203845110329182\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[8]\ttrain-mlogloss:0.95953508340719162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.747"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[9]\ttrain-mlogloss:0.91574316248848842\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[10]\ttrain-mlogloss:0.87405543661630625\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining rounds complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestClassifier(max_depth = -1, â€¦), â€¦).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.926\n",
      "Evaluating Decision Tree...\n",
      "Decision Tree Accuracy: 0.9166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DecisionTreeClassifier(max_depth = -1, â€¦), â€¦).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: DecisionTreeClassifier(max_depth = -1, â€¦)\n",
       "  args: \n",
       "    1:\tSource @666 âŽ Table{AbstractVector{Continuous}}\n",
       "    2:\tSource @831 âŽ AbstractVector{Multiclass{7}}\n"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate individual models\n",
    "println(\"Individual model performances:\")\n",
    "xgb_machine = evaluate_model(boosting_model, \"XGBoost\", X_table, y_cat, train, test)\n",
    "rf_machine = evaluate_model(forest_model, \"Random Forest\", X_table, y_cat, train, test)\n",
    "dt_machine = evaluate_model(d_tree_model, \"Decision Tree\", X_table, y_cat, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "voting_ensemble (generic function with 1 method)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed voting ensemble function for general models\n",
    "function voting_ensemble(machines, X_data; rows=nothing, weights=nothing)\n",
    "    # Get predictions (model-agnostic)\n",
    "    preds = isnothing(rows) ? \n",
    "        [MLJ.predict_mode(mach, X_data) for mach in machines] :\n",
    "        [MLJ.predict_mode(mach, X_data)[rows] for mach in machines]\n",
    "    \n",
    "    # Weight handling\n",
    "    weights = isnothing(weights) ? \n",
    "        ones(length(machines))/length(machines) : \n",
    "        weights ./ sum(weights)\n",
    "    \n",
    "    # Voting logic\n",
    "    all_classes = levels(preds[1])\n",
    "    result = similar(preds[1])\n",
    "    \n",
    "    for i in eachindex(result)\n",
    "        votes = Dict(cls => 0.0 for cls in all_classes)\n",
    "        for (j, p) in enumerate(preds)\n",
    "            votes[p[i]] += weights[j]\n",
    "        end\n",
    "        result[i] = argmax(votes)\n",
    "    end\n",
    "    \n",
    "    return result\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(XGBoostClassifier(test = 1, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mXGBoost: starting training.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[1]\ttrain-mlogloss:1.61594114078317785\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[2]\ttrain-mlogloss:1.44170167412866901\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[3]\ttrain-mlogloss:1.30709032945850989\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[4]\ttrain-mlogloss:1.20926078277180959\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[5]\ttrain-mlogloss:1.12804281678509222\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[6]\ttrain-mlogloss:1.07320544867204504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[7]\ttrain-mlogloss:1.00203845110329182\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[8]\ttrain-mlogloss:0.95953508340719162\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[9]\ttrain-mlogloss:0.91574316248848842\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m[10]\ttrain-mlogloss:0.87405543661630625\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining rounds complete.\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(RandomForestClassifier(max_depth = -1, â€¦), â€¦).\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(DecisionTreeClassifier(max_depth = -1, â€¦), â€¦).\n"
     ]
    }
   ],
   "source": [
    "using MLJ\n",
    "\n",
    "# Use a different name for your array of machines\n",
    "my_machines = [\n",
    "    machine(boosting_model, X_table, y_cat),\n",
    "    #svm_mach,  # Use the already trained SVM machine directly\n",
    "    machine(forest_model, X_table, y_cat),\n",
    "    machine(d_tree_model, X_table, y_cat)\n",
    "]\n",
    "\n",
    "# Fit all other machines on the training data\n",
    "for m in my_machines\n",
    "    #if m != svm_mach  # Skip the already trained SVM\n",
    "        fit!(m, rows=train)\n",
    "    #end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "voting_ensemble (generic function with 1 method)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLJ, Tables, Statistics, CategoricalArrays\n",
    "\n",
    "function voting_ensemble(machines, X_data; rows=nothing, weights=nothing)\n",
    "    # Convert to matrix, subset, then back to table\n",
    "    X_matrix = Tables.matrix(X_data)\n",
    "    X_subset = isnothing(rows) ? X_matrix : X_matrix[rows, :]\n",
    "    X_table = Tables.table(X_subset)\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    preds = [MLJ.predict(mach, X_table) for mach in machines]\n",
    "    \n",
    "    # Ensure weights are provided or use equal weights\n",
    "    if isnothing(weights)\n",
    "        weights = ones(length(machines)) / length(machines)\n",
    "    else\n",
    "        weights = weights ./ sum(weights) # Normalize weights\n",
    "    end\n",
    "    \n",
    "    # Combine predictions\n",
    "    if all(pred -> eltype(pred) <: UnivariateFinite, preds)\n",
    "        # Working with probability distributions\n",
    "        combined_probs = sum(p .* w for (p, w) in zip(preds, weights))\n",
    "        return mode.(combined_probs)\n",
    "    else\n",
    "        # Working with direct class predictions\n",
    "        n_instances = length(first(preds))\n",
    "        final_preds = Vector{Any}(undef, n_instances)\n",
    "        \n",
    "        for i in 1:n_instances\n",
    "            votes = Dict{Any, Float64}()\n",
    "            for (model_idx, pred) in enumerate(preds)\n",
    "                class = pred[i]\n",
    "                if class isa CategoricalArrays.CategoricalValue\n",
    "                    class = class.pool.levels[class.refs]\n",
    "                end\n",
    "                votes[class] = get(votes, class, 0.0) + weights[model_idx]\n",
    "            end\n",
    "            final_preds[i] = argmax(votes)\n",
    "        end\n",
    "        \n",
    "        # Convert to categorical if all predictions are integers\n",
    "        if all(x -> isa(x, Integer), final_preds)\n",
    "            return categorical(final_preds)\n",
    "        else\n",
    "            return final_preds\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Custom Voting Ensemble Accuracy: 0.9139\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using our custom voting ensemble\n",
    "ensemble_preds = voting_ensemble(my_machines, X_table; rows=test)\n",
    "\n",
    "# Convert predictions to categorical if necessary for comparison with true labels\n",
    "ensemble_preds_cat = categorical(ensemble_preds)\n",
    "\n",
    "# Calculate ensemble accuracy\n",
    "ensemble_acc = accuracy(ensemble_preds_cat, y_cat[test])\n",
    "println(\"\\nCustom Voting Ensemble Accuracy: \", round(ensemble_acc, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model accuracies for weighting:\n",
      "XGBoost: 0.747\n",
      "Random Forest: 0.926\n",
      "Decision Tree: 0.9166\n"
     ]
    }
   ],
   "source": [
    "# Try weighted voting based on individual model performance\n",
    "model_accs = [\n",
    "    accuracy(MLJ.predict_mode(xgb_machine; rows=test), y_cat[test]),\n",
    "    # accuracy(MLJ.predict_mode(svm_machine; rows=test), y_cat[test]),  # Uncomment if using SVM\n",
    "    accuracy(MLJ.predict_mode(rf_machine; rows=test), y_cat[test]),\n",
    "    accuracy(MLJ.predict_mode(dt_machine; rows=test), y_cat[test])\n",
    "]\n",
    "println(\"\\nModel accuracies for weighting:\")\n",
    "println(\"XGBoost: \", round(model_accs[1], digits=4))\n",
    "# println(\"SVM: \", round(model_accs[2], digits=4))  # Uncomment if using SVM\n",
    "println(\"Random Forest: \", round(model_accs[2], digits=4))  # Adjust index if not using SVM\n",
    "println(\"Decision Tree: \", round(model_accs[3], digits=4))  # Adjust index if not using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tournament simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68-element CategoricalArray{Int64,1,UInt32}:\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 3\n",
       " 1\n",
       " 4\n",
       " 2\n",
       " 1\n",
       " 1\n",
       " 3\n",
       " 1\n",
       " 1\n",
       " â‹®\n",
       " 4\n",
       " 1\n",
       " 1\n",
       " 4\n",
       " 1\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 5\n",
       " 1\n",
       " 1\n",
       " 1"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_float = Float64.(X_test)\n",
    "ensemble_preds = voting_ensemble(my_machines, X_test_float; rows=1:size(X_test_float, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5Ã—12 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">SEED</th><th style = \"text-align: left;\">ADJOE_rank</th><th style = \"text-align: left;\">ADJDE_rank</th><th style = \"text-align: left;\">BARTHAG_rank</th><th style = \"text-align: left;\">EFG%_rank</th><th style = \"text-align: left;\">EFGD%_rank</th><th style = \"text-align: left;\">TOR_rank</th><th style = \"text-align: left;\">TORD_rank</th><th style = \"text-align: left;\">ORB_rank</th><th style = \"text-align: left;\">DRB_rank</th><th style = \"text-align: left;\">TEAM</th><th style = \"text-align: left;\">ensemble_preds</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String31\" style = \"text-align: left;\">String31</th><th title = \"CategoricalValue{Int64, UInt32}\" style = \"text-align: left;\">Catâ€¦</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">182</td><td style = \"text-align: right;\">95</td><td style = \"text-align: right;\">31</td><td style = \"text-align: right;\">110</td><td style = \"text-align: right;\">137</td><td style = \"text-align: right;\">174</td><td style = \"text-align: right;\">76</td><td style = \"text-align: right;\">136</td><td style = \"text-align: left;\">Akron</td><td style = \"text-align: left;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">149</td><td style = \"text-align: right;\">348</td><td style = \"text-align: right;\">39</td><td style = \"text-align: right;\">149</td><td style = \"text-align: left;\">Alabama</td><td style = \"text-align: left;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">282</td><td style = \"text-align: right;\">247</td><td style = \"text-align: right;\">275</td><td style = \"text-align: right;\">325</td><td style = \"text-align: right;\">163</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">86</td><td style = \"text-align: right;\">228</td><td style = \"text-align: right;\">225</td><td style = \"text-align: left;\">Alabama St.</td><td style = \"text-align: left;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">268</td><td style = \"text-align: right;\">194</td><td style = \"text-align: right;\">243</td><td style = \"text-align: right;\">119</td><td style = \"text-align: right;\">242</td><td style = \"text-align: right;\">155</td><td style = \"text-align: right;\">139</td><td style = \"text-align: right;\">335</td><td style = \"text-align: right;\">62</td><td style = \"text-align: left;\">American</td><td style = \"text-align: left;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">83</td><td style = \"text-align: right;\">73</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">212</td><td style = \"text-align: right;\">19</td><td style = \"text-align: right;\">107</td><td style = \"text-align: left;\">Arizona</td><td style = \"text-align: left;\">3</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& SEED & ADJOE\\_rank & ADJDE\\_rank & BARTHAG\\_rank & EFG\\%\\_rank & EFGD\\%\\_rank & TOR\\_rank & TORD\\_rank & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 13 & 62 & 182 & 95 & 31 & 110 & 137 & 174 & $\\dots$ \\\\\n",
       "\t2 & 2 & 4 & 28 & 5 & 14 & 50 & 149 & 348 & $\\dots$ \\\\\n",
       "\t3 & 16 & 282 & 247 & 275 & 325 & 163 & 4 & 86 & $\\dots$ \\\\\n",
       "\t4 & 16 & 268 & 194 & 243 & 119 & 242 & 155 & 139 & $\\dots$ \\\\\n",
       "\t5 & 4 & 10 & 30 & 9 & 83 & 73 & 108 & 212 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5Ã—12 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0mâ”‚\u001b[1m SEED  \u001b[0m\u001b[1m ADJOE_rank \u001b[0m\u001b[1m ADJDE_rank \u001b[0m\u001b[1m BARTHAG_rank \u001b[0m\u001b[1m EFG%_rank \u001b[0m\u001b[1m EFGD%_rank \u001b[0m\u001b[1m TOR\u001b[0m â‹¯\n",
       "     â”‚\u001b[90m Int64 \u001b[0m\u001b[90m Int64      \u001b[0m\u001b[90m Int64      \u001b[0m\u001b[90m Int64        \u001b[0m\u001b[90m Int64     \u001b[0m\u001b[90m Int64      \u001b[0m\u001b[90m Int\u001b[0m â‹¯\n",
       "â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "   1 â”‚    13          62         182            95         31         110      â‹¯\n",
       "   2 â”‚     2           4          28             5         14          50\n",
       "   3 â”‚    16         282         247           275        325         163\n",
       "   4 â”‚    16         268         194           243        119         242\n",
       "   5 â”‚     4          10          30             9         83          73      â‹¯\n",
       "\u001b[36m                                                               6 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@assert length(ensemble_preds) == nrow() \"Number of predictions must match number of rows in df_test\"\n",
    "df_test[!, :ensemble_preds] = ensemble_preds\n",
    "first(df_test, 5) # View the first 5 rows to confirm the new column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5Ã—13 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">SEED</th><th style = \"text-align: left;\">ADJOE_rank</th><th style = \"text-align: left;\">ADJDE_rank</th><th style = \"text-align: left;\">BARTHAG_rank</th><th style = \"text-align: left;\">EFG%_rank</th><th style = \"text-align: left;\">EFGD%_rank</th><th style = \"text-align: left;\">TOR_rank</th><th style = \"text-align: left;\">TORD_rank</th><th style = \"text-align: left;\">ORB_rank</th><th style = \"text-align: left;\">DRB_rank</th><th style = \"text-align: left;\">TEAM</th><th style = \"text-align: left;\">ensemble_preds</th><th style = \"text-align: left;\">adjoe_adjde_diff</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String31\" style = \"text-align: left;\">String31</th><th title = \"CategoricalValue{Int64, UInt32}\" style = \"text-align: left;\">Catâ€¦</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">62</td><td style = \"text-align: right;\">182</td><td style = \"text-align: right;\">95</td><td style = \"text-align: right;\">31</td><td style = \"text-align: right;\">110</td><td style = \"text-align: right;\">137</td><td style = \"text-align: right;\">174</td><td style = \"text-align: right;\">76</td><td style = \"text-align: right;\">136</td><td style = \"text-align: left;\">Akron</td><td style = \"text-align: left;\">2</td><td style = \"text-align: right;\">-120</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">50</td><td style = \"text-align: right;\">149</td><td style = \"text-align: right;\">348</td><td style = \"text-align: right;\">39</td><td style = \"text-align: right;\">149</td><td style = \"text-align: left;\">Alabama</td><td style = \"text-align: left;\">2</td><td style = \"text-align: right;\">-24</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">282</td><td style = \"text-align: right;\">247</td><td style = \"text-align: right;\">275</td><td style = \"text-align: right;\">325</td><td style = \"text-align: right;\">163</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">86</td><td style = \"text-align: right;\">228</td><td style = \"text-align: right;\">225</td><td style = \"text-align: left;\">Alabama St.</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">35</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">16</td><td style = \"text-align: right;\">268</td><td style = \"text-align: right;\">194</td><td style = \"text-align: right;\">243</td><td style = \"text-align: right;\">119</td><td style = \"text-align: right;\">242</td><td style = \"text-align: right;\">155</td><td style = \"text-align: right;\">139</td><td style = \"text-align: right;\">335</td><td style = \"text-align: right;\">62</td><td style = \"text-align: left;\">American</td><td style = \"text-align: left;\">1</td><td style = \"text-align: right;\">74</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">30</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">83</td><td style = \"text-align: right;\">73</td><td style = \"text-align: right;\">108</td><td style = \"text-align: right;\">212</td><td style = \"text-align: right;\">19</td><td style = \"text-align: right;\">107</td><td style = \"text-align: left;\">Arizona</td><td style = \"text-align: left;\">3</td><td style = \"text-align: right;\">-20</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& SEED & ADJOE\\_rank & ADJDE\\_rank & BARTHAG\\_rank & EFG\\%\\_rank & EFGD\\%\\_rank & TOR\\_rank & TORD\\_rank & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 13 & 62 & 182 & 95 & 31 & 110 & 137 & 174 & $\\dots$ \\\\\n",
       "\t2 & 2 & 4 & 28 & 5 & 14 & 50 & 149 & 348 & $\\dots$ \\\\\n",
       "\t3 & 16 & 282 & 247 & 275 & 325 & 163 & 4 & 86 & $\\dots$ \\\\\n",
       "\t4 & 16 & 268 & 194 & 243 & 119 & 242 & 155 & 139 & $\\dots$ \\\\\n",
       "\t5 & 4 & 10 & 30 & 9 & 83 & 73 & 108 & 212 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5Ã—13 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0mâ”‚\u001b[1m SEED  \u001b[0m\u001b[1m ADJOE_rank \u001b[0m\u001b[1m ADJDE_rank \u001b[0m\u001b[1m BARTHAG_rank \u001b[0m\u001b[1m EFG%_rank \u001b[0m\u001b[1m EFGD%_rank \u001b[0m\u001b[1m TOR\u001b[0m â‹¯\n",
       "     â”‚\u001b[90m Int64 \u001b[0m\u001b[90m Int64      \u001b[0m\u001b[90m Int64      \u001b[0m\u001b[90m Int64        \u001b[0m\u001b[90m Int64     \u001b[0m\u001b[90m Int64      \u001b[0m\u001b[90m Int\u001b[0m â‹¯\n",
       "â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
       "   1 â”‚    13          62         182            95         31         110      â‹¯\n",
       "   2 â”‚     2           4          28             5         14          50\n",
       "   3 â”‚    16         282         247           275        325         163\n",
       "   4 â”‚    16         268         194           243        119         242\n",
       "   5 â”‚     4          10          30             9         83          73      â‹¯\n",
       "\u001b[36m                                                               7 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.adjoe_adjde_diff = df_test.ADJOE_rank - df_test.ADJDE_rank\n",
    "first(df_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simulate_single_elimination_tournament (generic function with 1 method)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, CategoricalArrays\n",
    "\n",
    "function simulate_single_elimination_tournament(df::DataFrame)\n",
    "    predictions_df = copy(df)\n",
    "    \n",
    "    # Convert CategoricalArray to numeric if needed\n",
    "    if isa(predictions_df.ensemble_preds, CategoricalArray)\n",
    "        # Option 1: If the values represent numbers, convert to integers\n",
    "        predictions_df.ensemble_preds = Int.(levelcode.(predictions_df.ensemble_preds))\n",
    "        \n",
    "        # Option 2: Alternatively, you could make the categorical array ordered\n",
    "        # ordered!(predictions_df.ensemble_preds, true)\n",
    "    end\n",
    "    \n",
    "    remaining_teams = collect(1:nrow(predictions_df))\n",
    "    round_winners = []\n",
    "    \n",
    "    for round_number in 1:6\n",
    "        println(\"Round $round_number:\")\n",
    "        if length(remaining_teams) == 1\n",
    "            println(\"Winner: $(predictions_df[remaining_teams[1], :TEAM])\")\n",
    "            break\n",
    "        end\n",
    "        \n",
    "        winners_this_round = []\n",
    "        # Pair up teams for this round\n",
    "        for i in 1:2:length(remaining_teams)\n",
    "            if i + 1 > length(remaining_teams)\n",
    "                # Handle odd number of teams - give a bye\n",
    "                push!(winners_this_round, remaining_teams[i])\n",
    "                println(\"$(predictions_df[remaining_teams[i], :TEAM]) gets a bye\")\n",
    "                continue\n",
    "            end\n",
    "            \n",
    "            team1 = remaining_teams[i]\n",
    "            team2 = remaining_teams[i + 1]\n",
    "            \n",
    "            # Determine the winner for this match\n",
    "            if predictions_df[team1, :ensemble_preds] > predictions_df[team2, :ensemble_preds]\n",
    "                winner = team1\n",
    "            elseif predictions_df[team1, :ensemble_preds] < predictions_df[team2, :ensemble_preds]\n",
    "                winner = team2\n",
    "            else\n",
    "                # If ensemble_preds are equal, compare adjoe_adjde_diff\n",
    "                if predictions_df[team1, :adjoe_adjde_diff] > predictions_df[team2, :adjoe_adjde_diff]\n",
    "                    winner = team1\n",
    "                else\n",
    "                    winner = team2\n",
    "                end\n",
    "            end\n",
    "            \n",
    "            push!(winners_this_round, winner)\n",
    "            println(\"$(predictions_df[team1, :TEAM]) vs $(predictions_df[team2, :TEAM]): Winner: $(predictions_df[winner, :TEAM])\")\n",
    "        end\n",
    "        \n",
    "        push!(round_winners, winners_this_round)\n",
    "        remaining_teams = winners_this_round\n",
    "    end\n",
    "    \n",
    "    return round_winners\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reorder_dataframe (generic function with 1 method)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, CategoricalArrays\n",
    "\n",
    "function reorder_dataframe(df_a, column_name, order_list)\n",
    "    \"\"\"\n",
    "    Filters and reorders the rows of a DataFrame based on a specified column and order list.\n",
    "    Parameters:\n",
    "        df_a (DataFrame): The DataFrame to be filtered and reordered.\n",
    "        column_name (Symbol or String): The name of the column used for filtering and reordering.\n",
    "        order_list (Vector): The list of values specifying the desired order.\n",
    "    Returns:\n",
    "        DataFrame: The filtered and reordered DataFrame.\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame\n",
    "    df = copy(df_a)\n",
    "    \n",
    "    # Convert column_name to Symbol if it's a String\n",
    "    col_sym = typeof(column_name) == String ? Symbol(column_name) : column_name\n",
    "    \n",
    "    # Ensure column_name exists in DataFrame\n",
    "    if !(col_sym in propertynames(df))\n",
    "        error(\"Column '$(col_sym)' does not exist in the DataFrame.\")\n",
    "    end\n",
    "    \n",
    "    # First filter the DataFrame to include only rows with values in order_list\n",
    "    filtered_df = filter(row -> row[col_sym] in order_list, df)\n",
    "    \n",
    "    # Check if we found all teams in the dataframe\n",
    "    found_teams = unique(filtered_df[:, col_sym])\n",
    "    missing_teams = setdiff(order_list, found_teams)\n",
    "    if !isempty(missing_teams)\n",
    "        @warn \"The following teams from order_list were not found in the DataFrame: $(missing_teams)\"\n",
    "    end\n",
    "    \n",
    "    # Create a dictionary mapping each value to its position in order_list\n",
    "    order_dict = Dict(value => i for (i, value) in enumerate(order_list))\n",
    "    \n",
    "    # Sort the filtered DataFrame based on the order specified in order_list\n",
    "    sorted_df = sort(filtered_df, col_sym, by = x -> get(order_dict, x, length(order_list) + 1))\n",
    "    \n",
    "    return sorted_df\n",
    "end\n",
    "\n",
    "# Example usage:\n",
    "# reordered_df = reorder_dataframe(tourny, :Team, desired_order)\n",
    "# println(reordered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using DataFrames\n",
    "\n",
    "function first4_dataframe(df, column_name, teams_of_interest)\n",
    "    # Filter the DataFrame where the specified column matches any of the teams of interest\n",
    "    filtered_df = filter(row -> row[column_name] in teams_of_interest, df)\n",
    "    return filtered_df\n",
    "end\n",
    "\n",
    "# Define the teams of interest for each DataFrame\n",
    "MW_1_teams = [\"Montana St.\", \"Grambling St.\"]\n",
    "MW_2_teams = [\"Virgina\", \"Colorado St.\"]\n",
    "S_teams = [\"Colorado\", \"Boise St.\"]\n",
    "SW_teams = [\"Wagner\", \"Howard\"]\n",
    "\n",
    "# Create DataFrames for each set of teams\n",
    "first_MW_1 = first4_dataframe(df_test, :TEAM, MW_1_teams)\n",
    "first_MW_2 = first4_dataframe(df_test, :TEAM, MW_2_teams)\n",
    "first_S = first4_dataframe(df_test, :TEAM, S_teams)\n",
    "first_SW = first4_dataframe(df_test, :TEAM, SW_teams)\n",
    "\n",
    "# Simulate tournaments for each group\n",
    "first_MW1_teams = simulate_single_elimination_tournament(first_MW_1)\n",
    "first_south_teams = simulate_single_elimination_tournament(first_S)\n",
    "first_MW2_teams = simulate_single_elimination_tournament(first_MW_2)\n",
    "first_southwest_teams = simulate_single_elimination_tournament(first_SW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1:\n",
      "Auburn vs Alabama St.: Winner: Auburn\n",
      "Louisville vs Creighton: Winner: Louisville\n",
      "Michigan vs UC San Diego: Winner: Michigan\n",
      "Texas A&M vs Yale: Winner: Texas A&M\n",
      "Mississippi vs North Carolina: Winner: Mississippi\n",
      "Iowa St. vs Lipscomb: Winner: Iowa St.\n",
      "Marquette vs New Mexico: Winner: New Mexico\n",
      "Michigan St. vs Bryant: Winner: Michigan St.\n",
      "Round 2:\n",
      "Auburn vs Louisville: Winner: Auburn\n",
      "Michigan vs Texas A&M: Winner: Michigan\n",
      "Mississippi vs Iowa St.: Winner: Iowa St.\n",
      "New Mexico vs Michigan St.: Winner: Michigan St.\n",
      "Round 3:\n",
      "Auburn vs Michigan: Winner: Auburn\n",
      "Iowa St. vs Michigan St.: Winner: Michigan St.\n",
      "Round 4:\n",
      "Auburn vs Michigan St.: Winner: Michigan St.\n",
      "Round 5:\n",
      "Winner: Michigan St.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Vector{Any}:\n",
       " Any[1, 3, 5, 7, 9, 11, 14, 15]\n",
       " Any[1, 5, 11, 15]\n",
       " Any[1, 15]\n",
       " Any[15]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the teams for each region\n",
    "\n",
    "\n",
    "south_teams = [\"Auburn\", \"Alabama St.\", \"Louisville\", \"Creighton\", \"Michigan\", \"UC San Diego\",\n",
    "\"Texas A&M\", \"Yale\", \"Mississippi\", \"North Carolina\", \"Iowa St.\", \"Lipscomb\",\n",
    "\"Marquette\", \"New Mexico\", \"Michigan St.\", \"Bryant\"]\n",
    "\n",
    "South_df = reorder_dataframe(df_test, :TEAM, south_teams)\n",
    "S_bracket = simulate_single_elimination_tournament(South_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1:\n",
      "Houston vs SIU Edwardsville: Winner: Houston\n",
      "Gonzaga vs Georgia: Winner: Gonzaga\n",
      "Clemson vs McNeese St.: Winner: Clemson\n",
      "Purdue vs High Point: Winner: Purdue\n",
      "Illinois vs Texas: Winner: Illinois\n",
      "Kentucky vs Troy: Winner: Kentucky\n",
      "UCLA vs Utah St.: Winner: UCLA\n",
      "Tennessee vs Wofford: Winner: Tennessee\n",
      "Round 2:\n",
      "Houston vs Gonzaga: Winner: Houston\n",
      "Clemson vs Purdue: Winner: Clemson\n",
      "Illinois vs Kentucky: Winner: Illinois\n",
      "UCLA vs Tennessee: Winner: UCLA\n",
      "Round 3:\n",
      "Houston vs Clemson: Winner: Clemson\n",
      "Illinois vs UCLA: Winner: UCLA\n",
      "Round 4:\n",
      "Clemson vs UCLA: Winner: UCLA\n",
      "Round 5:\n",
      "Winner: UCLA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Vector{Any}:\n",
       " Any[1, 3, 5, 7, 9, 11, 13, 15]\n",
       " Any[1, 5, 9, 13]\n",
       " Any[5, 13]\n",
       " Any[13]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw_teams = [\"Houston\", \"SIU Edwardsville\", \"Gonzaga\", \"Georgia\", \"Clemson\", \"McNeese St.\",\n",
    "\"Purdue\", \"High Point\", \"Illinois\", \"Texas\", \"Kentucky\", \"Troy\",\n",
    "\"UCLA\", \"Utah St.\", \"Tennessee\", \"Wofford\"]\n",
    "\n",
    "# Assuming reorder_dataframe function exists, set dataframes for each region\n",
    "MW_df = reorder_dataframe(df_test, :TEAM, mw_teams)\n",
    "MW_bracket = simulate_single_elimination_tournament(MW_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1:\n",
      "Duke vs Mount St. Mary's: Winner: Duke\n",
      "Mississippi St. vs Baylor: Winner: Mississippi St.\n",
      "Oregon vs Liberty: Winner: Liberty\n",
      "Arizona vs Akron: Winner: Arizona\n",
      "BYU vs VCU: Winner: BYU\n",
      "Wisconsin vs Montana: Winner: Wisconsin\n",
      "Saint Mary's vs Vanderbilt: Winner: Vanderbilt\n",
      "Alabama vs Robert Morris: Winner: Alabama\n",
      "Round 2:\n",
      "Duke vs Mississippi St.: Winner: Duke\n",
      "Liberty vs Arizona: Winner: Arizona\n",
      "BYU vs Wisconsin: Winner: Wisconsin\n",
      "Vanderbilt vs Alabama: Winner: Alabama\n",
      "Round 3:\n",
      "Duke vs Arizona: Winner: Duke\n",
      "Wisconsin vs Alabama: Winner: Wisconsin\n",
      "Round 4:\n",
      "Duke vs Wisconsin: Winner: Wisconsin\n",
      "Round 5:\n",
      "Winner: Wisconsin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Vector{Any}:\n",
       " Any[1, 3, 6, 7, 9, 11, 14, 15]\n",
       " Any[1, 7, 11, 15]\n",
       " Any[1, 11]\n",
       " Any[11]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "east_teams = [\"Duke\", \"Mount St. Mary's\", \"Mississippi St.\", \"Baylor\", \"Oregon\", \"Liberty\",\n",
    "\"Arizona\", \"Akron\", \"BYU\", \"VCU\", \"Wisconsin\", \"Montana\",\n",
    "\"Saint Mary's\", \"Vanderbilt\", \"Alabama\", \"Robert Morris\"]\n",
    "              \n",
    "E_df = reorder_dataframe(df_test, :TEAM, east_teams)\n",
    "E_bracket = simulate_single_elimination_tournament(E_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1:\n",
      "Florida vs Norfolk St.: Winner: Florida\n",
      "Connecticut vs Oklahoma: Winner: Oklahoma\n",
      "Memphis vs Colorado St.: Winner: Memphis\n",
      "Maryland vs Grand Canyon: Winner: Maryland\n",
      "Missouri vs Drake: Winner: Missouri\n",
      "UNC Wilmington vs Kansas: Winner: Kansas\n",
      "Arkansas vs St. John's: Winner: St. John's\n",
      "Texas Tech vs Nebraska Omaha: Winner: Texas Tech\n",
      "Round 2:\n",
      "Florida vs Oklahoma: Winner: Florida\n",
      "Memphis vs Maryland: Winner: Maryland\n",
      "Missouri vs Kansas: Winner: Kansas\n",
      "St. John's vs Texas Tech: Winner: Texas Tech\n",
      "Round 3:\n",
      "Florida vs Maryland: Winner: Florida\n",
      "Kansas vs Texas Tech: Winner: Texas Tech\n",
      "Round 4:\n",
      "Florida vs Texas Tech: Winner: Florida\n",
      "Round 5:\n",
      "Winner: Florida\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Vector{Any}:\n",
       " Any[1, 4, 5, 7, 9, 12, 14, 15]\n",
       " Any[1, 7, 12, 15]\n",
       " Any[1, 15]\n",
       " Any[1]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_teams = [\"Florida\", \"Norfolk St.\", \"Connecticut\", \"Oklahoma\", \"Memphis\", \"Colorado St.\",\n",
    "\"Maryland\", \"Grand Canyon\", \"Missouri\", \"Drake\", \"UNC Wilmington\", \"Kansas\",\n",
    "\"Arkansas\", \"St. John's\", \"Texas Tech\", \"Nebraska Omaha\"]\n",
    "\n",
    "W_df = reorder_dataframe(df_test, :TEAM, w_teams)\n",
    "W_bracket = simulate_single_elimination_tournament(W_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1:\n",
      "Florida vs Michigan St.: Winner: Michigan St.\n",
      "UCLA vs Wisconsin: Winner: Wisconsin\n",
      "Round 2:\n",
      "Michigan St. vs Wisconsin: Winner: Michigan St.\n",
      "Round 3:\n",
      "Winner: Michigan St.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " Any[2, 4]\n",
       " Any[2]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add region winners\n",
    "region_champs = [\"Florida\", \"Michigan St.\", \"UCLA\", \"Wisconsin\"]\n",
    "final4_df = reorder_dataframe(df_test, :TEAM, region_champs)\n",
    "\n",
    "# In Julia, we use dropmissing() instead of dropna()\n",
    "final4_df = dropmissing(final4_df)\n",
    "\n",
    "# Simulate the championship\n",
    "champs = simulate_single_elimination_tournament(final4_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
